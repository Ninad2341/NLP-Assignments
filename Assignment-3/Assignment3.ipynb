{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxEge2gVdgn5"
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    \"Natural Language Processing helps computers understand human language.\",\n",
        "    \"Text cleaning and preprocessing are important steps in NLP!\",\n",
        "    \"TF-IDF is widely used for document representation.\"\n",
        "]\n",
        "\n",
        "labels = [\"NLP\", \"Preprocessing\", \"Representation\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "cleaned_docs = [clean_text(doc) for doc in documents]\n",
        "print(cleaned_docs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rDrKLdod9gP",
        "outputId": "b8de2961-4990-4213-da35-4d11eb4f3b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural language processing helps computers understand human language', 'text cleaning and preprocessing are important steps in nlp', 'tfidf is widely used for document representation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_docs = [\n",
        "    \" \".join([lemmatizer.lemmatize(word) for word in doc.split()])\n",
        "    for doc in cleaned_docs\n",
        "]\n",
        "\n",
        "print(lemmatized_docs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxuxcFXAeAja",
        "outputId": "ef453578-321b-41e7-f5d6-7407ae425509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural language processing help computer understand human language', 'text cleaning and preprocessing are important step in nlp', 'tfidf is widely used for document representation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "final_docs = [\n",
        "    \" \".join([word for word in doc.split() if word not in ENGLISH_STOP_WORDS])\n",
        "    for doc in lemmatized_docs\n",
        "]\n",
        "\n",
        "print(final_docs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCdHU8CveItG",
        "outputId": "a2c60e9e-4968-43b1-f74f-40cb9f0684a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural language processing help computer understand human language', 'text cleaning preprocessing important step nlp', 'tfidf widely used document representation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoded_labels = encoder.fit_transform(labels)\n",
        "\n",
        "print(encoded_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzdGshTPeL3S",
        "outputId": "4aa2adf3-55c8-485f-9c43-e0f27f63e20f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(final_docs)\n",
        "\n",
        "print(tfidf.get_feature_names_out())\n",
        "print(tfidf_matrix.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVU4b6p8eNLC",
        "outputId": "045cfc82-3415-4b68-e3e5-dc9ca32b29de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cleaning' 'computer' 'document' 'help' 'human' 'important' 'language'\n",
            " 'natural' 'nlp' 'preprocessing' 'processing' 'representation' 'step'\n",
            " 'text' 'tfidf' 'understand' 'used' 'widely']\n",
            "[[0.         0.31622777 0.         0.31622777 0.31622777 0.\n",
            "  0.63245553 0.31622777 0.         0.         0.31622777 0.\n",
            "  0.         0.         0.         0.31622777 0.         0.        ]\n",
            " [0.40824829 0.         0.         0.         0.         0.40824829\n",
            "  0.         0.         0.40824829 0.40824829 0.         0.\n",
            "  0.40824829 0.40824829 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.4472136  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.4472136\n",
            "  0.         0.         0.4472136  0.         0.4472136  0.4472136 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Save cleaned text\n",
        "pd.DataFrame({\"cleaned_text\": final_docs}).to_csv(\"cleaned_text.csv\", index=False)\n",
        "\n",
        "# Save TF-IDF matrix\n",
        "tfidf_df = pd.DataFrame(\n",
        "    tfidf_matrix.toarray(),\n",
        "    columns=tfidf.get_feature_names_out()\n",
        ")\n",
        "tfidf_df.to_csv(\"tfidf_features.csv\", index=False)\n",
        "\n",
        "# Save encoded labels\n",
        "pd.DataFrame({\"labels\": encoded_labels}).to_csv(\"labels.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "52GzkU8aeR5B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}